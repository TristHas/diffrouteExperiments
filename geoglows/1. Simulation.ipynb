{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc3dc5c8-eaa2-4bfe-8111-2e6e2a4cb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from diffroute import LTIRouter, get_node_idxs, read_params\n",
    "\n",
    "from src.schedule import define_schedule\n",
    "from src.cat_interp import CatchmentInterpolator\n",
    "from src.geoglow_io import extract_all_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bae242d-3ab9-4cf7-b799-b6f0f52b8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to set the correct download path in src/config\n",
    "from src.config import DATA_ROOT as root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea28347-5f48-4c0d-a14e-2ec1da76c3aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_sim(clusters_g, node_transfer, cat):\n",
    "    step_time = defaultdict(float) \n",
    "    outputs   = []\n",
    "    transfered_inputs = {i: [] for i, _ in enumerate(clusters_g)}\n",
    "\n",
    "    for i, g in enumerate(tqdm(clusters_g)):\n",
    "        nodes_idx = get_node_idxs(g)\n",
    "\n",
    "        params = (\n",
    "            read_params(g, model_name, nodes_idx)\n",
    "            .float()\n",
    "            .to(device, non_blocking=True)\n",
    "        )\n",
    "\n",
    "        model = LTIRouter(\n",
    "            g,\n",
    "            nodes_idx=nodes_idx,\n",
    "            max_delay=time_window,\n",
    "            block_size=block_size,\n",
    "            irf_fn=model_name,\n",
    "            irf_agg=irf_agg,\n",
    "            index_precomp=index_precomp,\n",
    "            runoff_to_output=runoff_to_output,\n",
    "            dt=dt,\n",
    "            sampling_mode=sample_mode,\n",
    "        ).to(device)\n",
    "        model.aggregator.init_buffers(device)\n",
    "\n",
    "        x = cat.read_catchment(i) \n",
    "        \n",
    "        for e_dst, inp_dis in transfered_inputs[i]: x[:, e_dst] += inp_dis.squeeze()\n",
    "\n",
    "        out = model(x.to(device, non_blocking=True), params)\n",
    "        \n",
    "        for (c_idx, e_src, e_dst) in node_transfer[i]: transfered_inputs[c_idx].append((e_dst, out[:, e_src].clone().detach()))\n",
    "        \n",
    "        output = pd.DataFrame(out.cpu().squeeze(), index=nodes_idx.index, columns=runoff.index).T\n",
    "        outputs.append(output)\n",
    "        \n",
    "    outputs = pd.concat(outputs, axis=1).loc[q.index] / 86400.0\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe1aba-5396-4b82-ad0b-7796b1cc3d58",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ed0a6-c4d7-4691-a1ee-d613f334f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep important parameters here\n",
    "time_window=30\n",
    "dt=1/24\n",
    "block_size=16\n",
    "\n",
    "model_name=\"muskingum\"\n",
    "irf_agg=\"log_triton\"\n",
    "index_precomp=\"cpu\"\n",
    "sample_mode=\"avg\"\n",
    "\n",
    "plength_thr=10**5 # Maximum depth of 100,000 pathes per cluster\n",
    "node_thr=10**4    # Maximum width of 10,000 nodes per cluster\n",
    "device = \"cuda:5\"\n",
    "runoff_to_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb080cf-dd39-49bb-bf79-28e2450d7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_root = root / 'configs'\n",
    "root_discharge = root / \"retro_feather\"\n",
    "runoff = pd.read_feather(root / \"daily_sparse_runoff.feather\")\n",
    "interp_df = pd.read_feather(root / \"interp_weight.feather\")\n",
    "vpus = [x.stem for x in root_discharge.glob(\"*\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7a66b-52e9-46c7-8f38-29fc8b1ab3f2",
   "metadata": {},
   "source": [
    "### First numerical eval.\n",
    "\n",
    "- Here, we compute vpu by vpu to facilitate evaluation.\n",
    "- It takes a lot of time as we have a lot of redundant IO, but it is still faster than doing the global evaluation in-memory because:\n",
    "    - With global evaluation we need to manipulate pandas of >1TB for evaluation -> memory blow out\n",
    "    - That blows up memory and even half dataset variance computations take hours.\n",
    "- Hence, we evaluate per VPU and do the fast timing in global execution below, it is simpler and results are the same.\n",
    "- We should find a solution to unify the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0c64d-dc95-4a93-af2b-9892c9ee5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for vpu in tqdm(vpus):\n",
    "    G = extract_all_graphs(config_root, [vpu])\n",
    "    for n in G.nodes: G.nodes[n][\"k\"] /= (3600*24)\n",
    "\n",
    "    clusters_g, node_transfer = define_schedule(G, plength_thr=plength_thr, node_thr=node_thr)\n",
    "    cat = CatchmentInterpolator(clusters_g, runoff, interp_df, device=device)\n",
    "\n",
    "    print(\"reading river discharges...\")\n",
    "    q = pd.read_feather(root_discharge / f\"{vpu}.feather\")\n",
    "    qvar = q.var()\n",
    "    qmean = q.mean()\n",
    "    \n",
    "    print(\"Running model...\")\n",
    "    out  = run_sim(clusters_g, node_transfer, cat)\n",
    "    \n",
    "\n",
    "    nse = 1 - ((out - q)**2).mean() / qvar\n",
    "    mae = (out-q).abs().mean()\n",
    "\n",
    "    res.append((nse, mae, qmean, qvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0db4b409-1c41-4488-846e-97627c8c777e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.9996492)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nse, mae, qmean, qvar = zip(*res)\n",
    "nse, mae, qmean, qvar = [pd.concat(x) for x in [nse, mae, qmean, qvar]]\n",
    "nse.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ceaec-beee-461f-9e27-4a2f8ac9c72b",
   "metadata": {},
   "source": [
    "### Second, global timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6530d1f-212d-4b81-a85f-78d65ada5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync   = torch.cuda.synchronize      \n",
    "\n",
    "def run_sim_timed(clusters_g, node_transfer, cat):\n",
    "    step_time = defaultdict(float)   \n",
    "    outputs   = []\n",
    "    transfered_inputs = {i: [] for i, _ in enumerate(clusters_g)}\n",
    "\n",
    "    for i, g in enumerate(tqdm(clusters_g)):\n",
    "\n",
    "        # ── Step‑1 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        nodes_idx = get_node_idxs(g)\n",
    "        step_time[1] += time.perf_counter() - t0                # CPU only\n",
    "\n",
    "        # ── Step‑2 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        params = (\n",
    "            read_params(g, model_name, nodes_idx)\n",
    "            .float()\n",
    "            .to(device, non_blocking=True)\n",
    "        )\n",
    "        sync(device)                                            # wait for copy\n",
    "        step_time[2] += time.perf_counter() - t0\n",
    "\n",
    "        # ── Step‑3 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        model = LTIRouter(\n",
    "            g,\n",
    "            nodes_idx=nodes_idx,\n",
    "            max_delay=time_window,\n",
    "            block_size=block_size,\n",
    "            irf_fn=model_name,\n",
    "            irf_agg=irf_agg,\n",
    "            index_precomp=index_precomp,\n",
    "            runoff_to_output=runoff_to_output,\n",
    "            dt=dt,\n",
    "            sampling_mode=sample_mode,\n",
    "        ).to(device)\n",
    "        model.aggregator.init_buffers(device)\n",
    "        sync(device)\n",
    "        step_time[3] += time.perf_counter() - t0\n",
    "\n",
    "        # ── Step‑4 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        x = cat.read_catchment(i)        # usually CPU → GPU happens later\n",
    "        step_time[4] += time.perf_counter() - t0\n",
    "\n",
    "        # ── Step‑5 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        for e_dst, inp_dis in transfered_inputs[i]: x[:, e_dst] += inp_dis.squeeze()\n",
    "        step_time[5] += time.perf_counter() - t0                # CPU tensor ops\n",
    "\n",
    "        # ── Step‑6 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        out = model(x.to(device, non_blocking=True), params)\n",
    "        sync(device)                                            # wait for kernel\n",
    "        step_time[6] += time.perf_counter() - t0\n",
    "\n",
    "        # ── Step‑7 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        for (c_idx, e_src, e_dst) in node_transfer[i]: transfered_inputs[c_idx].append((e_dst, out[:, e_src].clone().detach()))\n",
    "        step_time[7] += time.perf_counter() - t0                # small CPU work\n",
    "\n",
    "        # ── Step‑8 ───────────────────────────────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "        output = pd.DataFrame(out.cpu().squeeze(), index=nodes_idx.index, columns=runoff.index).T\n",
    "        outputs.append(output)\n",
    "        step_time[8] += time.perf_counter() - t0\n",
    "\n",
    "    # ── Final report ────────────────────────────────────────────\n",
    "    total = sum(step_time.values())\n",
    "    print(\"\\n=== cumulative run‑time by step (s) ===\")\n",
    "    for k in range(1, 9):\n",
    "        print(f\"Step {k}: {step_time[k]:8.3f} s  ({step_time[k]/total:5.1%})\")\n",
    "    print(f\"Total: {total:8.3f} s\")\n",
    "\n",
    "    return model, step_time, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00962d4-aed8-4ced-95c0-facfd2d5537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading runoffs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92af90352e1c49c6ae669c22b9561914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Upstream stats computations ... ####\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5476efdf3d534ddfa22dbd3321ad44a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing breakpoints:   0%|          | 0/6838900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Segmentation into subgraphs ... ####\n",
      "Removing edges...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b8ab3be945435da5c31993182de061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6838900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment graph into connected components....\n",
      "Build subgraphs for each cluster and node-cluster map...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03bbc44c05244a6b8fd547555224083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104665 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establish dependencies between clusters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6076c5b2fcb4ce0ac9027f8328ac18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70044 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Grouping subgraphs to cluster and infering dependencies ... ####\n",
      "Initialize dependencies...\n",
      "Associate clusters for remaining subgraphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febefdd9cee14450b09328c88ab76cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging graphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8cb08a55c2468cbdf5ed74bcf32558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing merged graphs node idxs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fa81c20f264cccb52a9def890f570c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match breakpoint nodes across clusters...\n",
      "#### Cluster Annotations ... ####\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cd22a187a3495faa5585ce0a6c40fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load full global dataset\n",
    "G, runoff, interp_df = load_geoflow(vpu_numbers=None)\n",
    "clusters_g, node_transfer = define_schedule(G, plength_thr=plength_thr, node_thr=node_thr)\n",
    "cat = CatchmentInterpolator(clusters_g, runoff, interp_df, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46979ef-02c7-41b6-b482-5938078ba2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa7effed6494ae7b8bd526cab144384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== cumulative run‑time by step (s) ===\n",
      "Step 1:   10.809 s  ( 2.8%)\n",
      "Step 2:   49.479 s  (12.6%)\n",
      "Step 3:  148.009 s  (37.8%)\n",
      "Step 4:    0.148 s  ( 0.0%)\n",
      "Step 5:    0.000 s  ( 0.0%)\n",
      "Step 6:  182.918 s  (46.7%)\n",
      "Step 7:    0.000 s  ( 0.0%)\n",
      "Step 8:    0.000 s  ( 0.0%)\n",
      "Total:  391.364 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LTIRouter(\n",
       "   (aggregator): RoutingIRFAggregator()\n",
       "   (conv): BlockSparseCausalConv()\n",
       " ),\n",
       " defaultdict(float,\n",
       "             {1: 10.808951897546649,\n",
       "              2: 49.47939977608621,\n",
       "              3: 148.00921990536153,\n",
       "              4: 0.14795606583356857,\n",
       "              6: 182.91803489252925,\n",
       "              5: 0.0,\n",
       "              7: 0.0,\n",
       "              8: 0.0}),\n",
       " [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First execution is slower (why: It probably is triton JIT compile overhead)\n",
    "run_sim_timed(clusters_g, node_transfer, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8ffcbb9-cbea-4d55-ad3d-923727310ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4463f3461945c58f39dfe8019596d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== cumulative run‑time by step (s) ===\n",
      "Step 1:    9.510 s  ( 4.0%)\n",
      "Step 2:   22.298 s  ( 9.4%)\n",
      "Step 3:  131.652 s  (55.4%)\n",
      "Step 4:    0.123 s  ( 0.1%)\n",
      "Step 5:    0.000 s  ( 0.0%)\n",
      "Step 6:   74.030 s  (31.2%)\n",
      "Step 7:    0.000 s  ( 0.0%)\n",
      "Step 8:    0.000 s  ( 0.0%)\n",
      "Total:  237.613 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LTIRouter(\n",
       "   (aggregator): RoutingIRFAggregator()\n",
       "   (conv): BlockSparseCausalConv()\n",
       " ),\n",
       " defaultdict(float,\n",
       "             {1: 9.509653015062213,\n",
       "              2: 22.298364767804742,\n",
       "              3: 131.65237718820572,\n",
       "              4: 0.12266553193330765,\n",
       "              6: 74.03042277693748,\n",
       "              5: 0.0,\n",
       "              7: 0.0,\n",
       "              8: 0.0}),\n",
       " [])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second execution is fast. \n",
    "# Step 6 is routing. \n",
    "# Step 1 is computing node_idxs, Step 2 is parameter reading, Step 3 is model init and Step 4 is interpolating catchments.\n",
    "run_sim_timed(clusters_g, node_transfer, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72e853-a4a1-4a0d-946a-b1f6a29339dc",
   "metadata": {},
   "source": [
    "# Comments on speed:\n",
    "- Routing itself is fast.\n",
    "- When saving everything to CPU, time is dominated by CPU manipulation of the output (step 8).\n",
    "- We should optimize this, overlap IO with compute  and probably have a CPU-side process doing the formatting on CPU with a pinned memory tensor to receive data.\n",
    "- But wether putting the efforts to do this is worth it depends on the needs of applications.\n",
    "- Hence, please reach out if you use this code so we can identify the needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a08d5c-5b5c-447c-902f-c9f9fb5140a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
